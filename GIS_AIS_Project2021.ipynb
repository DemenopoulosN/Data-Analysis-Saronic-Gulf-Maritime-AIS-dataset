{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Geographical Information Systems</center>**\n",
    "### **<center>Final Project - Part B</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import helper\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "PLT_FIG_WIDTH = 4.487\n",
    "PLT_FIG_HEIGHT = PLT_FIG_WIDTH / 1.618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'Documents', 'DataStories-UniPi', 'ST_Visions'))\n",
    "import st_visualizer\n",
    "import express as viz_express\n",
    "import geom_helper as viz_helper\n",
    "\n",
    "import bokeh.palettes as bokeh_palettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with PostgreSQL database and fetching our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "con = psycopg2.connect(database=\"database_GIS\", user=\"postgres\", password=\"polifolio68\", host=\"localhost\", port=5432)\n",
    "\n",
    "# fetching ais_dataset\n",
    "ais_dataset = \"SELECT * FROM ais_dataset;\"\n",
    "df = gpd.GeoDataFrame.from_postgis(ais_dataset, con, geom_col=\"point\")\n",
    "\n",
    "# fetching ais_routes\n",
    "# df_routes = \"SELECT * FROM ais_routes;\"\n",
    "# gdf_routes = gpd.GeoDataFrame.from_postgis(df_routes, con, geom_col=\"routes\")\n",
    "\n",
    "# fetching attica_points\n",
    "attica_coordinates = \"SELECT * FROM attica_points;\"\n",
    "attica_points = gpd.GeoDataFrame.from_postgis(attica_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching salamina_points\n",
    "salamina_coordinates = \"SELECT * FROM salamina_points;\"\n",
    "salamina_points = gpd.GeoDataFrame.from_postgis(salamina_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching aegina_points\n",
    "aegina_coordinates = \"SELECT * FROM aegina_points;\"\n",
    "aegina_points = gpd.GeoDataFrame.from_postgis(aegina_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching agistri_points\n",
    "agistri_coordinates = \"SELECT * FROM agistri_points;\"\n",
    "agistri_points = gpd.GeoDataFrame.from_postgis(agistri_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis=1)\n",
    "\n",
    "# converting data types of columns\n",
    "df[[\"timestamp\",\"mmsi\"]] = df[[\"timestamp\",\"mmsi\"]].apply(pd.to_numeric)\n",
    "df[[\"lon\", \"lat\",\"heading\",\"speed\",\"course\"]] = df[[\"lon\", \"lat\",\"heading\",\"speed\",\"course\"]].astype(float)\n",
    "attica_points[[\"lon\", \"lat\"]] = attica_points[[\"lon\", \"lat\"]].astype(float)\n",
    "salamina_points[[\"lon\", \"lat\"]] = salamina_points[[\"lon\", \"lat\"]].astype(float)\n",
    "aegina_points[[\"lon\", \"lat\"]] = aegina_points[[\"lon\", \"lat\"]].astype(float)\n",
    "agistri_points[[\"lon\", \"lat\"]] = agistri_points[[\"lon\", \"lat\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes\n",
    "# attica_points.dtypes\n",
    "# salamina_points.dtypes\n",
    "# aegina_points.dtypes\n",
    "# agistri_points.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exploratory Statistical Analysis</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize it on the map using ST_Visions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(df.head(30000))\n",
    "\n",
    "viz_express.plot_points_on_map(st_viz, tools=['lasso_select'])\n",
    "st_viz.add_temporal_filter(temporal_name='timestamp', temporal_unit='ms', callback_policy='value_throttled', step_ms=5*60*10**3, title='Temporal Horizon')\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### Number of vessels & records (AIS signals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.mmsi.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To get the average number of AIS signals per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([pd.to_datetime(df.timestamp,unit=\"ms\").dt.date]).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To get the number of records (AIS signals) per vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mmsi').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To get the (mean) number of records (AIS signals) per vessel at daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby([\"mmsi\", pd.to_datetime(df.timestamp,unit=\"ms\").dt.date]).apply(len)\n",
    "tmp.groupby('mmsi').apply(lambda x: x.sum()/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To get the number of records (AIS signals) per weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname = df.groupby([pd.to_datetime(df.timestamp, unit=\"ms\").dt.date]).apply(len).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname.loc[:, 'day_name'] = pd.to_datetime(recs_per_dayname.timestamp).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have exactly what we want, but something is off (spoiler: the days are not sorted!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname.sort_values('day_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting does not work. Or it works perfectly? Pandas does not understand categorical sorting; its default behaviour is to either sort *lexicographically*, *numerically*, or **categorically** depending on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname.loc[:, 'day_name'] = pd.Categorical(recs_per_dayname.day_name, categories=list(calendar.day_name), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_per_dayname.sort_values('day_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "recs_per_dayname.day_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Statistical Analysis (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### Plot the distribution of the number of AIS signals per vessel (Python3/Matplotlib code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_records_per_vessel = df.groupby('mmsi').apply(len)\n",
    "\n",
    "out = pd.cut(number_of_records_per_vessel, [0, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, number_of_records_per_vessel.max()]) \n",
    "ax = out.value_counts(sort=False).plot.bar(figsize=(PLT_FIG_WIDTH,PLT_FIG_HEIGHT), fontsize=8, width=0.75, cmap='tab20', rot=40)\n",
    "\n",
    "\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.suptitle(r'Distribution of the number of AIS signals per vessel', fontsize=8, y=1)\n",
    "plt.xlabel(r'#AIS signals', fontsize=8)\n",
    "plt.ylabel(r'#vessels', fontsize=8)\n",
    "\n",
    "plt.savefig(os.path.join('.', 'png', 'number_of_records_per_vessel.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Distribution of the number of records (AIS activity) per vessel at daily basis;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_records_per_vessel_per_day = df.groupby([df.mmsi, pd.to_datetime(df.timestamp, unit='ms').dt.date]).apply(len)\n",
    "number_of_records_per_vessel_per_day = number_of_records_per_vessel_per_day.groupby('mmsi').apply(lambda x: x.sum()/len(x))\n",
    "\n",
    "out = pd.cut(number_of_records_per_vessel_per_day, [0, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, number_of_records_per_vessel_per_day.max()]) \n",
    "ax = out.value_counts(sort=False).plot.bar(figsize=(PLT_FIG_WIDTH,PLT_FIG_HEIGHT), fontsize=8, width=0.75, cmap='tab20', rot=30)\n",
    "\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.suptitle(r'Distribution of AIS activity per vessel at daily basis', fontsize=8, y=1)\n",
    "plt.xlabel(r'#AIS signals', fontsize=8)\n",
    "plt.ylabel(r'#vessels', fontsize=8)\n",
    "\n",
    "plt.savefig(os.path.join('.', 'png', 'AIS_Signals_per_vessel_per_day.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To plot the distribution of the number of AIS signals per weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_records_per_day = df.groupby([pd.to_datetime(df.timestamp, unit=\"ms\").dt.date]).apply(len).to_frame().reset_index()\n",
    "no_of_records_per_day.loc[:, 'day_name'] = pd.to_datetime(no_of_records_per_day.timestamp).dt.day_name()\n",
    "no_of_records_per_day.loc[:, 'day_name'] = pd.Categorical(no_of_records_per_day.day_name, categories=list(calendar.day_name), ordered=True)\n",
    "no_of_records_per_day.sort_values('day_name', inplace=True)\n",
    "\n",
    "no_of_records_per_day.plot.bar(cmap='tab20', x='day_name', figsize=(PLT_FIG_WIDTH,PLT_FIG_HEIGHT), fontsize=8, width=0.75, legend=False, rot=30)\n",
    "\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.suptitle(r'AIS activity per weekday', fontsize=8, y=1)\n",
    "plt.xlabel(r'', fontsize=8)\n",
    "plt.ylabel(r'#records', fontsize=8)\n",
    "\n",
    "plt.savefig(os.path.join('.', 'png', 'AIS_Signals_per_Weekday.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Data Preprocessing </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General cleansing on ais_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(df):\n",
    "    # Converting time from msec. to sec.\n",
    "    df.loc[:, 'timestamp_sec'] = df.timestamp/10**3\n",
    "\n",
    "    # Remove duplicate points\n",
    "    df.drop_duplicates(subset=['timestamp','mmsi'], inplace=True)\n",
    "\n",
    "    print ('Step 1. Calculating Speed')\n",
    "    # Calculate speed\n",
    "    calc_velocity = df.copy().groupby('mmsi', group_keys=False).apply(lambda gdf: helper.calculate_velocity(gdf, spd_column='speed', ts_column='timestamp_sec'))['velocity']\n",
    "\n",
    "    print ('Step 2. Calculating Bearing')\n",
    "    # Calculate bearing\n",
    "    calc_heading = df.copy().groupby('mmsi', group_keys=False).apply(lambda gdf: helper.calculate_bearing(gdf))['bearing']\n",
    "\n",
    "    print ('Step 3. Concatenating Results')\n",
    "    df.loc[:, 'velocity'] = calc_velocity\n",
    "    df.loc[:, 'bearing'] = calc_heading\n",
    "\n",
    "    print ('Step 4. Calculating Acceleration')\n",
    "    # Calculate acceleration\n",
    "    df = df.groupby('mmsi', group_keys=False).apply(lambda gdf: helper.calculate_acceleration(gdf, ts_column='timestamp_sec'))\n",
    "\n",
    "    # Drop NaN values (in case they exist)\n",
    "    df.dropna(subset=['velocity', 'bearing', 'acceleration'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. Calculating Speed\n",
      "Step 2. Calculating Bearing\n",
      "Step 3. Concatenating Results\n",
      "Step 4. Calculating Acceleration\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = preprocessing_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleansing depending on distance from papei antenna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "point_Papei = Point(37.9414940, 23.652832)\n",
    "point_random = Point(38.000074, 23.743337)\n",
    "# haversine(37.9414940, 23.652832 , df.loc[:, 'lat'], df.loc[:, 'lon'])\n",
    "\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# empDfObj = pd.DataFrame(df, columns=['lon', 'lat'])\n",
    "df_test = df[['lon','lat']]\n",
    "\n",
    "\n",
    "i = 0\n",
    "for element in df.lon:\n",
    "#     print(haversine(37.9414940, 23.652832 , df.loc[i, 'lat'], df.loc[i, 'lon']))\n",
    "    df.loc[:, 'distance_from_papei'] = haversine(37.9414940, 23.652832 , df.loc[i, 'lat'], df.loc[i, 'lon'])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine(37.9414940, 23.652832, 38.031918, 23.529105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_traj_gdf.loc[:, 'distance_from_prev'] = vessel_traj_gdf.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (vessel_traj_gdf.iloc[l.name+1].geom.x, vessel_traj_gdf.iloc[l.name+1].geom.y,))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'distance_from_papei'] = df.iloc[:-1].apply(lambda l: helper.haversine((37.9414940, 23.652832), (df.lat, df.lon))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine(37.9414940, 23.652832, 37.944813, 23.614868)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions' outline datasets cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#κρατάμε μόνο το νότιο τμήμα της αττικ΄ής που μας ενδιαφέρει\n",
    "attica_points_new = attica_points.loc[attica_points.lon < 23.7820177].copy()\n",
    "attica_points_new = attica_points_new.loc[attica_points_new.lon > 23.1789667]\n",
    "attica_points_new = attica_points_new.loc[attica_points_new.lat < 38.0463491]\n",
    "attica_points_new = attica_points_new.loc[attica_points_new.lat > 37.8118874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geom</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>23.180479</td>\n",
       "      <td>37.952114</td>\n",
       "      <td>POINT (23.18048 37.95211)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>23.181643</td>\n",
       "      <td>37.952396</td>\n",
       "      <td>POINT (23.18164 37.95240)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23.182833</td>\n",
       "      <td>37.952123</td>\n",
       "      <td>POINT (23.18283 37.95212)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>23.183436</td>\n",
       "      <td>37.951927</td>\n",
       "      <td>POINT (23.18344 37.95193)</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>23.183970</td>\n",
       "      <td>37.951853</td>\n",
       "      <td>POINT (23.18397 37.95185)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>23.781708</td>\n",
       "      <td>37.811937</td>\n",
       "      <td>POINT (23.78171 37.81194)</td>\n",
       "      <td>10862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>23.781798</td>\n",
       "      <td>37.811927</td>\n",
       "      <td>POINT (23.78180 37.81193)</td>\n",
       "      <td>10863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>23.781806</td>\n",
       "      <td>37.811975</td>\n",
       "      <td>POINT (23.78181 37.81197)</td>\n",
       "      <td>10864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>23.781855</td>\n",
       "      <td>37.812002</td>\n",
       "      <td>POINT (23.78186 37.81200)</td>\n",
       "      <td>10865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>23.781929</td>\n",
       "      <td>37.811957</td>\n",
       "      <td>POINT (23.78193 37.81196)</td>\n",
       "      <td>10866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10192 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat                       geom     id\n",
       "40     23.180479  37.952114  POINT (23.18048 37.95211)     40\n",
       "41     23.181643  37.952396  POINT (23.18164 37.95240)     41\n",
       "42     23.182833  37.952123  POINT (23.18283 37.95212)     42\n",
       "43     23.183436  37.951927  POINT (23.18344 37.95193)     43\n",
       "44     23.183970  37.951853  POINT (23.18397 37.95185)     44\n",
       "...          ...        ...                        ...    ...\n",
       "10862  23.781708  37.811937  POINT (23.78171 37.81194)  10862\n",
       "10863  23.781798  37.811927  POINT (23.78180 37.81193)  10863\n",
       "10864  23.781806  37.811975  POINT (23.78181 37.81197)  10864\n",
       "10865  23.781855  37.812002  POINT (23.78186 37.81200)  10865\n",
       "10866  23.781929  37.811957  POINT (23.78193 37.81196)  10866\n",
       "\n",
       "[10192 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attica_points_new   #έμειναν 10192 εγγραφές από τις 27923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by id\n",
    "attica_points_new = attica_points_new.sort_values('id').reset_index(drop=True)\n",
    "#Calculate distance from previous (in meters)\n",
    "attica_points_new.loc[:, 'distance_from_prev'] = attica_points_new.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (attica_points_new.iloc[l.name+1].geom.x, attica_points_new.iloc[l.name+1].geom.y,))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by id\n",
    "salamina_points_new = salamina_points.sort_values('id').reset_index(drop=True)\n",
    "#Calculate distance from previous (in meters)\n",
    "salamina_points_new.loc[:, 'distance_from_prev'] = salamina_points_new.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (salamina_points_new.iloc[l.name+1].geom.x, salamina_points_new.iloc[l.name+1].geom.y,))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by id\n",
    "aegina_points_new = aegina_points.sort_values('id').reset_index(drop=True)\n",
    "#Calculate distance from previous (in meters)\n",
    "aegina_points_new.loc[:, 'distance_from_prev'] = aegina_points_new.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (aegina_points_new.iloc[l.name+1].geom.x, aegina_points_new.iloc[l.name+1].geom.y,))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by id\n",
    "agistri_points_new = agistri_points.sort_values('id').reset_index(drop=True)\n",
    "#Calculate distance from previous (in meters)\n",
    "agistri_points_new.loc[:, 'distance_from_prev'] = agistri_points_new.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (agistri_points_new.iloc[l.name+1].geom.x, agistri_points_new.iloc[l.name+1].geom.y,))*1000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#βλέπουμε πόσες εγγραφές θα κρατήσουμε από κάθε περιοχή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attica_points_new.loc[attica_points_new.distance_from_prev > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salamina_points_new.loc[salamina_points_new.distance_from_prev > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aegina_points_new.loc[aegina_points_new.distance_from_prev > 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agistri_points_new.loc[agistri_points_new.distance_from_prev > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#τελικά κρατάμε τις εγγραφές που θέλουμε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "attica_points_new = attica_points_new.loc[attica_points_new.distance_from_prev > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "salamina_points_new = salamina_points_new.loc[salamina_points_new.distance_from_prev > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "aegina_points_new = aegina_points_new.loc[aegina_points_new.distance_from_prev > 65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "agistri_points_new = agistri_points_new.loc[agistri_points_new.distance_from_prev > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geom</th>\n",
       "      <th>id</th>\n",
       "      <th>distance_from_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23.180479</td>\n",
       "      <td>37.952114</td>\n",
       "      <td>POINT (23.18048 37.95211)</td>\n",
       "      <td>40</td>\n",
       "      <td>106.774472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.181643</td>\n",
       "      <td>37.952396</td>\n",
       "      <td>POINT (23.18164 37.95240)</td>\n",
       "      <td>41</td>\n",
       "      <td>108.641390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>23.184991</td>\n",
       "      <td>37.951969</td>\n",
       "      <td>POINT (23.18499 37.95197)</td>\n",
       "      <td>48</td>\n",
       "      <td>113.602151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>23.186074</td>\n",
       "      <td>37.952530</td>\n",
       "      <td>POINT (23.18607 37.95253)</td>\n",
       "      <td>49</td>\n",
       "      <td>134.112120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>23.197402</td>\n",
       "      <td>37.954173</td>\n",
       "      <td>POINT (23.19740 37.95417)</td>\n",
       "      <td>86</td>\n",
       "      <td>103.327546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>9697</td>\n",
       "      <td>23.750071</td>\n",
       "      <td>37.849567</td>\n",
       "      <td>POINT (23.75007 37.84957)</td>\n",
       "      <td>9738</td>\n",
       "      <td>149.634159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>9698</td>\n",
       "      <td>23.751455</td>\n",
       "      <td>37.848782</td>\n",
       "      <td>POINT (23.75145 37.84878)</td>\n",
       "      <td>9739</td>\n",
       "      <td>157.077467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>9857</td>\n",
       "      <td>23.768357</td>\n",
       "      <td>37.833501</td>\n",
       "      <td>POINT (23.76836 37.83350)</td>\n",
       "      <td>9898</td>\n",
       "      <td>121.047710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9874</td>\n",
       "      <td>23.770304</td>\n",
       "      <td>37.830143</td>\n",
       "      <td>POINT (23.77030 37.83014)</td>\n",
       "      <td>9915</td>\n",
       "      <td>174.020344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>10164</td>\n",
       "      <td>23.770795</td>\n",
       "      <td>37.811928</td>\n",
       "      <td>POINT (23.77079 37.81193)</td>\n",
       "      <td>10205</td>\n",
       "      <td>385.458788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index        lon        lat                       geom     id  \\\n",
       "0        0  23.180479  37.952114  POINT (23.18048 37.95211)     40   \n",
       "1        1  23.181643  37.952396  POINT (23.18164 37.95240)     41   \n",
       "2        8  23.184991  37.951969  POINT (23.18499 37.95197)     48   \n",
       "3        9  23.186074  37.952530  POINT (23.18607 37.95253)     49   \n",
       "4       46  23.197402  37.954173  POINT (23.19740 37.95417)     86   \n",
       "..     ...        ...        ...                        ...    ...   \n",
       "319   9697  23.750071  37.849567  POINT (23.75007 37.84957)   9738   \n",
       "320   9698  23.751455  37.848782  POINT (23.75145 37.84878)   9739   \n",
       "321   9857  23.768357  37.833501  POINT (23.76836 37.83350)   9898   \n",
       "322   9874  23.770304  37.830143  POINT (23.77030 37.83014)   9915   \n",
       "323  10164  23.770795  37.811928  POINT (23.77079 37.81193)  10205   \n",
       "\n",
       "     distance_from_prev  \n",
       "0            106.774472  \n",
       "1            108.641390  \n",
       "2            113.602151  \n",
       "3            134.112120  \n",
       "4            103.327546  \n",
       "..                  ...  \n",
       "319          149.634159  \n",
       "320          157.077467  \n",
       "321          121.047710  \n",
       "322          174.020344  \n",
       "323          385.458788  \n",
       "\n",
       "[324 rows x 6 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attica_points_new.reset_index()\n",
    "# salamina_points_new.reset_index()\n",
    "# aegina_points_new.reset_index()\n",
    "# agistri_points_new.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "attica_points_new = attica_points_new.drop(attica_points_new.distance_from_prev.name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "salamina_points_new = salamina_points_new.drop(salamina_points_new.distance_from_prev.name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "aegina_points_new = aegina_points_new.drop(aegina_points_new.distance_from_prev.name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "agistri_points_new = agistri_points_new.drop(agistri_points_new.distance_from_prev.name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attica_points_new.drop(attica_points_new.geometry.name, axis=1).to_csv('./attica_points_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "salamina_points_new.drop(salamina_points_new.geometry.name, axis=1).to_csv('./salamina_points_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "aegina_points_new.drop(aegina_points_new.geometry.name, axis=1).to_csv('./aegina_points_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "agistri_points_new.drop(agistri_points_new.geometry.name, axis=1).to_csv('./agistri_points_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to Postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql://postgres:polifolio68@localhost:5432/database_GIS')\n",
    "\n",
    "\n",
    "\n",
    "postgreSQLConnection    = engine.connect();\n",
    "\n",
    "postgreSQLTable_Attica         = \"attica_points\";\n",
    "postgreSQLTable_Salamina       = \"salamina_points\";\n",
    "postgreSQLTable_Aegina         = \"aegina_points\";\n",
    "postgreSQLTable_Agistri        = \"agistri_points\";\n",
    "\n",
    " \n",
    "\n",
    "try:\n",
    "    geodataframe_Attica    = attica_points_new.to_postgis(postgreSQLTable_Attica, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('POINT', srid= 2100)})\n",
    "    geodataframe_Salamina    = salamina_points_new.to_postgis(postgreSQLTable_Salamina, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('POINT', srid= 2100)})\n",
    "    geodataframe_Aegina    = aegina_points_new.to_postgis(postgreSQLTable_Aegina, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('POINT', srid= 2100)})\n",
    "    geodataframe_Agistri    = agistri_points_new.to_postgis(postgreSQLTable_Agistri, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('POINT', srid= 2100)})\n",
    "\n",
    "except ValueError as vx:\n",
    "\n",
    "    print(vx)\n",
    "\n",
    "except Exception as ex:  \n",
    "\n",
    "    print(ex)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable_Attica);\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable_Salamina);\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable_Aegina);\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable_Agistri);\n",
    "\n",
    "finally:\n",
    "\n",
    "    postgreSQLConnection.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sampling Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling_rate = df[['timestamp', 'mmsi']].sort_values(by=['mmsi','timestamp']).reset_index(drop=True)\n",
    "df_sampling_rate.head(50) \n",
    "df_sampling_rate.timestamp.diff()\n",
    "df_sampling_rate.timestamp.diff().mean()\n",
    "df_sampling_rate.timestamp.diff().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# για κάποιο τυχαίο mmsi κάθε φορά\n",
    "\n",
    "df_speed_sequence = df[df['mmsi'] == 240806000].reset_index(drop=True)\n",
    "df_speed_sequence.speed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# μετά τον καθαρισμό του dataset\n",
    "\n",
    "# χρησιμοποιώντας τη στήλη velocity που δημιουργείται μέσω της helper προκύπτουν 3296511  +++++ \n",
    "df_new = df.loc[df.velocity < 40].copy()\n",
    "df_new\n",
    "\n",
    "# χρησιμοποιώντας τη στήλη speed προκύπτουν 3299245  ++++ \n",
    "df_new2 = df.loc[df.speed < 40].copy()\n",
    "df_new2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 R-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from geopandas import GeoDataFrame as gdf\n",
    "sindex = df.geom.sindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cleaned ais dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(df_new.geometry.name, axis=1).to_csv('./ais_dataset_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql://postgres:polifolio68@localhost:5432/database_GIS')\n",
    "\n",
    "\n",
    "postgreSQLConnection    = engine.connect();\n",
    "\n",
    "postgreSQLTable         = \"ais_dataset\";\n",
    "\n",
    "\n",
    "try:\n",
    "    geodataframe    = df_new.to_postgis(postgreSQLTable, engine, if_exists='replace', index=False, \n",
    "                         dtype={'point': Geometry('POINT', srid= 2100)})\n",
    "except ValueError as vx:\n",
    "\n",
    "    print(vx)\n",
    "\n",
    "except Exception as ex:  \n",
    "\n",
    "    print(ex)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable);\n",
    "    \n",
    "finally:\n",
    "\n",
    "    postgreSQLConnection.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Statistics after pre-proccessing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To plot the distribution of the vessels' speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.cut(df.velocity, [0, 10, 20, 30, 40, 50, 60, np.round(df.velocity.max()), np.round(df.velocity.max())+2])\n",
    "ax = out.value_counts(sort=False).plot.area(figsize=(PLT_FIG_WIDTH,PLT_FIG_HEIGHT), fontsize=8, cmap='tab20', rot=0)\n",
    "ax.set_xticklabels([''] + out.cat.categories.left.values.astype(int).tolist() + [''])\n",
    "\n",
    "plt.suptitle(r'Vessel speed distribution', fontsize=8, y=1)\n",
    "plt.xlabel(r'speed (knots)', fontsize=8)\n",
    "plt.ylabel(r'#records', fontsize=8)\n",
    "\n",
    "plt.savefig(os.path.join('.', 'png', 'Vessel_Velocity_Distribution_V2.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To plot the distribution of the vessels' acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_bins=[-2000, -10, -2, -0.5, -0.25, -0.1, 0, 0.1, 0.25, 0.5, 2, 10, 2000] \n",
    "\n",
    "out = pd.cut(df.acceleration, no_of_bins)\n",
    "ax = out.value_counts(sort=False).plot.area(figsize=(PLT_FIG_WIDTH,PLT_FIG_HEIGHT), fontsize=8, cmap='tab20', rot=45)\n",
    "\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.suptitle(r'Vessel acceleration distribution', fontsize=8)\n",
    "plt.xlabel(r'acceleration (knots/s)', fontsize=8)\n",
    "plt.ylabel(r'#records', fontsize=8)\n",
    "\n",
    "plt.savefig(os.path.join('.', 'png', 'Vessel_Acceleration_Distribution.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ### To plot the distribution of the vessels' bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT_FIG_WIDTH = 4\n",
    "PLT_FIG_HEIGHT = PLT_FIG_WIDTH / 1.618\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.rcParams[\"figure.figsize\"] = [PLT_FIG_WIDTH, PLT_FIG_HEIGHT]\n",
    "\n",
    "bins_number = 24  # the [0, 360) interval will be subdivided into this number of equal bins\n",
    "degree_intervals = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax, lines, labels = helper.create_radial_chart(ax, df, bins_number, degree_intervals)\n",
    "\n",
    "ax.legend([r'#records (x$10^6$)'], frameon=False, fancybox=False, shadow=False, loc='lower center', bbox_to_anchor=(0.5, -0.25))\n",
    "plt.savefig(os.path.join('.', 'png', 'Vessel_Course_Distribution_V8.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Checkpoint_: Save Calculated Sensor-Based Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['geom'], axis=1).to_csv('ais_dataset_pp.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helper.getGeoDataFrame_v2(pd.read_csv('ais_dataset_pp.csv'), crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Spatial Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_traj_gdf = df.loc[(df.mmsi == 237024500)].sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "vessel_traj_gdf.loc[:, 'distance_from_prev'] = vessel_traj_gdf.iloc[:-1].apply(lambda l: helper.haversine((l.geom.x, l.geom.y), (vessel_traj_gdf.iloc[l.name+1].geom.x, vessel_traj_gdf.iloc[l.name+1].geom.y,))*1000, axis=1)\n",
    "vessel_traj_gdf.loc[:, 'temporal_difference_from_prev'] = vessel_traj_gdf.timestamp_sec.diff().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pts = np.array(vessel_traj_gdf.loc[vessel_traj_gdf.velocity >= 40].index)\n",
    "prev_pts = vessel_traj_gdf.loc[vessel_traj_gdf.velocity >= 40].index - 1\n",
    "next_pts = vessel_traj_gdf.loc[vessel_traj_gdf.velocity >= 40].index + 1\n",
    "\n",
    "sub_traj_of_interest = vessel_traj_gdf.iloc[np.sort(np.concatenate((prev_pts, next_pts, \n",
    "                                                                    vessel_traj_gdf.loc[vessel_traj_gdf.velocity >= 40].index)))]\\\n",
    "                                      .drop_duplicates(subset=['mmsi', 'timestamp_sec'])\n",
    "\n",
    "sub_traj_of_interest.head(7).style.apply(lambda l: helper.highlight_outliers(l, curr_pts), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Example Using ST_Visions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sub_traj_of_interest.copy()\n",
    "tmp.loc[:, 'cat'] = (tmp.loc[:, 'velocity'] >= 40).astype(str)\n",
    "tmp_traj = viz_helper.create_linestring_from_points(tmp, 'mmsi')\n",
    "\n",
    "\n",
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(tmp)\n",
    "\n",
    "st_viz.create_canvas(title=f'Spatial Outliers', sizing_mode='scale_width', plot_width=540, plot_height=150)\n",
    "st_viz.add_map_tile('CARTODBPOSITRON')\n",
    "\n",
    "st_viz.add_categorical_colormap(palette=bokeh_palettes.Category10_3, categorical_name='cat')\n",
    "circ = st_viz.add_glyph(glyph_type='circle', size=10, color=st_viz.cmap, alpha=0.8, fill_alpha=0.7, muted_alpha=0, legend_group=f'cat')\n",
    "\n",
    "tooltips = [('Vessel ID','@mmsi'), ('Timestamp','@timestamp_sec'), ('Speed (knots)','@velocity'),('Course over Ground (degrees)','@course'), ('Heading (degrees)','@heading'), ('Coordinates','(@lon, @lat)')]\n",
    "st_viz.add_hover_tooltips(tooltips)\n",
    "st_viz.add_lasso_select()\n",
    "\n",
    "\n",
    "st_viz_trajectories = st_visualizer.st_visualizer()\n",
    "st_viz_trajectories.set_data(tmp_traj)\n",
    "st_viz_trajectories.set_figure(st_viz.figure)\n",
    "\n",
    "st_viz_trajectories.create_source()\n",
    "st_viz_trajectories.add_line(line_color='skyblue', line_width=3, alpha=0.5)\n",
    "\n",
    "st_viz_trajectories.renderers[0].level = 'underlay'\n",
    "st_viz_trajectories.show_figures(notebook=True, sizing_mode='stretch_width', notebook_url='http://localhost:8888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's Remove the Outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.loc[df.velocity < 40].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mmsi</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>heading</th>\n",
       "      <th>speed</th>\n",
       "      <th>course</th>\n",
       "      <th>timestamp_sec</th>\n",
       "      <th>velocity</th>\n",
       "      <th>bearing</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1533081601000</td>\n",
       "      <td>240806000</td>\n",
       "      <td>23.668622</td>\n",
       "      <td>37.938845</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>POINT (23.66862 37.93885)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1533081601000</td>\n",
       "      <td>319327000</td>\n",
       "      <td>23.680805</td>\n",
       "      <td>37.930570</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.090061</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>-0.042026</td>\n",
       "      <td>POINT (23.68080 37.93057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1533081601000</td>\n",
       "      <td>239864200</td>\n",
       "      <td>23.614895</td>\n",
       "      <td>37.944807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257.5</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.103812</td>\n",
       "      <td>189.183093</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>POINT (23.61490 37.94481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1533081601000</td>\n",
       "      <td>240370000</td>\n",
       "      <td>23.667983</td>\n",
       "      <td>37.937883</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.051463</td>\n",
       "      <td>POINT (23.66798 37.93788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1533081602000</td>\n",
       "      <td>305213000</td>\n",
       "      <td>23.536395</td>\n",
       "      <td>37.897468</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>95.1</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>159.129855</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>POINT (23.53639 37.89747)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310076</th>\n",
       "      <td>1533686379000</td>\n",
       "      <td>241420000</td>\n",
       "      <td>23.639235</td>\n",
       "      <td>37.946098</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1.533686e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>POINT (23.63923 37.94610)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310077</th>\n",
       "      <td>1533686379000</td>\n",
       "      <td>240025700</td>\n",
       "      <td>23.551497</td>\n",
       "      <td>37.954000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.533686e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (23.55150 37.95400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310078</th>\n",
       "      <td>1533686379000</td>\n",
       "      <td>237008100</td>\n",
       "      <td>23.641363</td>\n",
       "      <td>37.944708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.533686e+09</td>\n",
       "      <td>0.279001</td>\n",
       "      <td>55.499580</td>\n",
       "      <td>-0.044946</td>\n",
       "      <td>POINT (23.64136 37.94471)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310079</th>\n",
       "      <td>1533686383000</td>\n",
       "      <td>237008100</td>\n",
       "      <td>23.641368</td>\n",
       "      <td>37.944712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.533686e+09</td>\n",
       "      <td>0.458783</td>\n",
       "      <td>44.127244</td>\n",
       "      <td>0.114375</td>\n",
       "      <td>POINT (23.64137 37.94471)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310080</th>\n",
       "      <td>1533686386000</td>\n",
       "      <td>237008100</td>\n",
       "      <td>23.641373</td>\n",
       "      <td>37.944717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.533686e+09</td>\n",
       "      <td>0.115660</td>\n",
       "      <td>71.034884</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>POINT (23.64137 37.94472)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3296511 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp       mmsi        lon        lat  heading  speed  \\\n",
       "0        1533081601000  240806000  23.668622  37.938845    297.0    0.0   \n",
       "1        1533081601000  319327000  23.680805  37.930570     71.0    0.0   \n",
       "2        1533081601000  239864200  23.614895  37.944807      NaN    0.0   \n",
       "3        1533081601000  240370000  23.667983  37.937883    251.0    0.0   \n",
       "4        1533081602000  305213000  23.536395  37.897468    345.0    0.1   \n",
       "...                ...        ...        ...        ...      ...    ...   \n",
       "3310076  1533686379000  241420000  23.639235  37.946098     36.0    0.1   \n",
       "3310077  1533686379000  240025700  23.551497  37.954000     94.0    0.0   \n",
       "3310078  1533686379000  237008100  23.641363  37.944708      NaN    0.0   \n",
       "3310079  1533686383000  237008100  23.641368  37.944712      NaN    0.0   \n",
       "3310080  1533686386000  237008100  23.641373  37.944717      NaN    0.0   \n",
       "\n",
       "         course  timestamp_sec  velocity     bearing  acceleration  \\\n",
       "0           0.1   1.533082e+09  0.008141  180.000000      0.000035   \n",
       "1          57.8   1.533082e+09  0.090061  180.000000     -0.042026   \n",
       "2         257.5   1.533082e+09  0.103812  189.183093      0.002516   \n",
       "3         335.0   1.533082e+09  0.000000    0.000000     -0.051463   \n",
       "4          95.1   1.533082e+09  0.678284  159.129855      0.055412   \n",
       "...         ...            ...       ...         ...           ...   \n",
       "3310076   286.0   1.533686e+09  0.000000    0.000000     -0.005098   \n",
       "3310077   180.0   1.533686e+09  0.000000    0.000000      0.000000   \n",
       "3310078     NaN   1.533686e+09  0.279001   55.499580     -0.044946   \n",
       "3310079     NaN   1.533686e+09  0.458783   44.127244      0.114375   \n",
       "3310080     NaN   1.533686e+09  0.115660   71.034884      0.002988   \n",
       "\n",
       "                              geom  \n",
       "0        POINT (23.66862 37.93885)  \n",
       "1        POINT (23.68080 37.93057)  \n",
       "2        POINT (23.61490 37.94481)  \n",
       "3        POINT (23.66798 37.93788)  \n",
       "4        POINT (23.53639 37.89747)  \n",
       "...                            ...  \n",
       "3310076  POINT (23.63923 37.94610)  \n",
       "3310077  POINT (23.55150 37.95400)  \n",
       "3310078  POINT (23.64136 37.94471)  \n",
       "3310079  POINT (23.64137 37.94471)  \n",
       "3310080  POINT (23.64137 37.94472)  \n",
       "\n",
       "[3296511 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.mmsi.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(df_new.geometry.name, axis=1).to_csv('./ais_dataset_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data processing and analytics</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'geom_helper' from 'C:\\\\Users\\\\Konstantinos\\\\Jupyter Notebook\\\\geom_helper.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(helper)\n",
    "importlib.reload(viz_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Konstantinos\\Jupyter Notebook\\ais_dataset_clean.csv', sep=',')\n",
    "df.sort_values('timestamp', inplace=True)\n",
    "df = helper.getGeoDataFrame_v2(df, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "attica_points = pd.read_csv(r'C:\\Users\\Konstantinos\\Jupyter Notebook\\attica_points_clean.csv', sep=',')\n",
    "attica_points = helper.getGeoDataFrame_v2(attica_points, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "salamina_points = pd.read_csv(r'C:\\Users\\Konstantinos\\Jupyter Notebook\\salamina_points_clean.csv', sep=',')\n",
    "salamina_points = helper.getGeoDataFrame_v2(salamina_points, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aegina_points = pd.read_csv(r'C:\\Users\\Konstantinos\\Jupyter Notebook\\aegina_points_clean.csv', sep=',')\n",
    "aegina_points = helper.getGeoDataFrame_v2(aegina_points, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "agistri_points = pd.read_csv(r'C:\\Users\\Konstantinos\\Jupyter Notebook\\agistri_points_clean.csv', sep=',')\n",
    "agistri_points = helper.getGeoDataFrame_v2(agistri_points, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from postgres tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "con = psycopg2.connect(database=\"database_GIS\", user=\"postgres\", password=\"polifolio68\", host=\"localhost\", port=5432)\n",
    "\n",
    "# fetching ais_dataset\n",
    "ais_dataset = \"SELECT * FROM ais_dataset;\"\n",
    "df = gpd.GeoDataFrame.from_postgis(ais_dataset, con, geom_col=\"point\")\n",
    "\n",
    "# fetching ais_routes\n",
    "# df_routes = \"SELECT * FROM ais_routes;\"\n",
    "# gdf_routes = gpd.GeoDataFrame.from_postgis(df_routes, con, geom_col=\"routes\")\n",
    "\n",
    "# fetching attica_points\n",
    "attica_coordinates = \"SELECT * FROM attica_points;\"\n",
    "attica_points = gpd.GeoDataFrame.from_postgis(attica_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching salamina_points\n",
    "salamina_coordinates = \"SELECT * FROM salamina_points;\"\n",
    "salamina_points = gpd.GeoDataFrame.from_postgis(salamina_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching aegina_points\n",
    "aegina_coordinates = \"SELECT * FROM aegina_points;\"\n",
    "aegina_points = gpd.GeoDataFrame.from_postgis(aegina_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "# fetching agistri_points\n",
    "agistri_coordinates = \"SELECT * FROM agistri_points;\"\n",
    "agistri_points = gpd.GeoDataFrame.from_postgis(agistri_coordinates, con, geom_col=\"geom\")\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate coordinates\n",
    "frames = [attica_points, salamina_points, aegina_points, agistri_points]\n",
    "regions_points = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_points = regions_points.drop(regions_points.id.name, axis=1)\n",
    "#regions_points.reset_index()\n",
    "\n",
    "#Adding 'id' column to dataframe\n",
    "regions_points.loc[:, 'id'] = regions_points.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geom</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.180479</td>\n",
       "      <td>37.952114</td>\n",
       "      <td>POINT (23.18048 37.95211)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.181643</td>\n",
       "      <td>37.952396</td>\n",
       "      <td>POINT (23.18164 37.95240)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.184991</td>\n",
       "      <td>37.951969</td>\n",
       "      <td>POINT (23.18499 37.95197)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.186074</td>\n",
       "      <td>37.952530</td>\n",
       "      <td>POINT (23.18607 37.95253)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.197402</td>\n",
       "      <td>37.954173</td>\n",
       "      <td>POINT (23.19740 37.95417)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>23.327241</td>\n",
       "      <td>37.675368</td>\n",
       "      <td>POINT (23.32724 37.67537)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>23.327869</td>\n",
       "      <td>37.674866</td>\n",
       "      <td>POINT (23.32787 37.67487)</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>23.328561</td>\n",
       "      <td>37.674808</td>\n",
       "      <td>POINT (23.32856 37.67481)</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>23.331396</td>\n",
       "      <td>37.674246</td>\n",
       "      <td>POINT (23.33140 37.67425)</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>23.332637</td>\n",
       "      <td>37.674114</td>\n",
       "      <td>POINT (23.33264 37.67411)</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lon        lat                       geom  id\n",
       "0   23.180479  37.952114  POINT (23.18048 37.95211)   0\n",
       "1   23.181643  37.952396  POINT (23.18164 37.95240)   1\n",
       "2   23.184991  37.951969  POINT (23.18499 37.95197)   2\n",
       "3   23.186074  37.952530  POINT (23.18607 37.95253)   3\n",
       "4   23.197402  37.954173  POINT (23.19740 37.95417)   4\n",
       "..        ...        ...                        ...  ..\n",
       "57  23.327241  37.675368  POINT (23.32724 37.67537)  57\n",
       "58  23.327869  37.674866  POINT (23.32787 37.67487)  58\n",
       "59  23.328561  37.674808  POINT (23.32856 37.67481)  59\n",
       "60  23.331396  37.674246  POINT (23.33140 37.67425)  60\n",
       "61  23.332637  37.674114  POINT (23.33264 37.67411)  61\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Raw Points, along with Attica's outline, on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(df.iloc[:3000, :].copy())\n",
    "viz_express.plot_points_on_map(st_viz, tools=['lasso_select'])\n",
    "\n",
    "\n",
    "regions_points_viz = st_visualizer.st_visualizer()\n",
    "regions_points_viz.set_data(regions_points.copy())\n",
    "regions_points_viz.set_figure(st_viz.figure)\n",
    "regions_points_viz.create_source()\n",
    "regions_points_viz.add_glyph(glyph_type='circle', size=10, color='crimson', alpha=0.8, fill_alpha=0.7, muted_alpha=0, legend_label='Regions\\' outline points')\n",
    "\n",
    "\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffering outline points' Geometry to aproximate their original (Polygon) Geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radius = 0.5km\n",
    "regions_points.geometry = regions_points.geometry.to_crs(epsg=2100).buffer(500).to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(df.iloc[:3000, :].copy())\n",
    "viz_express.plot_points_on_map(st_viz, tools=['lasso_select'])\n",
    "\n",
    "\n",
    "regions_points_viz = st_visualizer.st_visualizer()\n",
    "regions_points_viz.set_data(regions_points.copy())\n",
    "regions_points_viz.set_figure(st_viz.figure)\n",
    "regions_points_viz.create_source()\n",
    "regions_points_viz.add_polygon(fill_color='crimson', line_color='crimson', legend_label='Regions\\' outline points')\n",
    "\n",
    "\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying trajectories based on land proximity and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Create spatial index on Raw Points\n",
    "sindex = df.sindex\n",
    "#sindex = df.geom.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Find the points that intersect with each subpolygon and add them to points_within_geometry\n",
    "points_within_geometry = pd.DataFrame()\n",
    "\n",
    "for poly in regions_points.geometry:\n",
    "    #Find approximate matches with r-tree\n",
    "    possible_matches_index = list(sindex.intersection(poly.bounds))\n",
    "    possible_matches = df.iloc[possible_matches_index]\n",
    "    #Then intersect with the actual geometry in order to get the precise matches\n",
    "    precise_matches = possible_matches[possible_matches.intersects(poly)]\n",
    "    points_within_geometry = points_within_geometry.append(precise_matches)\n",
    "    \n",
    "points_within_geometry = points_within_geometry.drop_duplicates(subset=['mmsi','timestamp'])\n",
    "stationary_points_within_geometry = points_within_geometry.loc[points_within_geometry['velocity'] < 1.000000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'traj_id'] = 0\n",
    "df.loc[stationary_points_within_geometry.index, 'traj_id'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_points_within_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_within_geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.iloc[:3000, :].copy()\n",
    "tmp.traj_id = tmp.traj_id.apply(str)\n",
    "\n",
    "\n",
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(tmp.copy())\n",
    "st_viz.create_canvas('Prototype Plot')\n",
    "\n",
    "cmap = st_viz.add_categorical_colormap(('crimson','royalblue'), 'traj_id')\n",
    "st_viz.add_glyph(color=cmap, legend_label='Regions\\' outline points')\n",
    "st_viz.add_map_tile(provider='CARTODBPOSITRON')\n",
    "\n",
    "\n",
    "regions_points_viz = st_visualizer.st_visualizer()\n",
    "regions_points_viz.set_data(regions_points.copy())\n",
    "regions_points_viz.set_figure(st_viz.figure)\n",
    "regions_points_viz.create_source()\n",
    "regions_points_viz.add_polygon(fill_color=None, line_color='crimson', legend_label='Regions\\' outline points')\n",
    "\n",
    "\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Trajectories' Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helper.create_trajectories(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this point onward we'll focus on a single object, without loss of generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>heading</th>\n",
       "      <th>speed</th>\n",
       "      <th>course</th>\n",
       "      <th>timestamp_sec</th>\n",
       "      <th>velocity</th>\n",
       "      <th>bearing</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>traj_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmsi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201100152</th>\n",
       "      <td>1.533299e+12</td>\n",
       "      <td>23.551511</td>\n",
       "      <td>37.940764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.026128</td>\n",
       "      <td>123.947895</td>\n",
       "      <td>1.533299e+09</td>\n",
       "      <td>5.071104</td>\n",
       "      <td>131.484013</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201100182</th>\n",
       "      <td>1.533299e+12</td>\n",
       "      <td>23.516615</td>\n",
       "      <td>37.913168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.758721</td>\n",
       "      <td>127.036773</td>\n",
       "      <td>1.533299e+09</td>\n",
       "      <td>6.737374</td>\n",
       "      <td>126.183349</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.001453</td>\n",
       "      <td>-0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205339310</th>\n",
       "      <td>1.533196e+12</td>\n",
       "      <td>23.643233</td>\n",
       "      <td>37.926513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>183.742857</td>\n",
       "      <td>1.533196e+09</td>\n",
       "      <td>5.437462</td>\n",
       "      <td>186.354599</td>\n",
       "      <td>-0.004437</td>\n",
       "      <td>-0.046512</td>\n",
       "      <td>-0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205519630</th>\n",
       "      <td>1.533414e+12</td>\n",
       "      <td>23.649500</td>\n",
       "      <td>37.934933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786713</td>\n",
       "      <td>141.380000</td>\n",
       "      <td>1.533414e+09</td>\n",
       "      <td>0.794071</td>\n",
       "      <td>170.195586</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>-0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207137000</th>\n",
       "      <td>1.533434e+12</td>\n",
       "      <td>23.590206</td>\n",
       "      <td>37.894143</td>\n",
       "      <td>174.741078</td>\n",
       "      <td>2.476614</td>\n",
       "      <td>208.829309</td>\n",
       "      <td>1.533434e+09</td>\n",
       "      <td>2.490082</td>\n",
       "      <td>218.698913</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>-0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636092530</th>\n",
       "      <td>1.533130e+12</td>\n",
       "      <td>23.609716</td>\n",
       "      <td>37.880522</td>\n",
       "      <td>184.559361</td>\n",
       "      <td>9.483790</td>\n",
       "      <td>163.990868</td>\n",
       "      <td>1.533130e+09</td>\n",
       "      <td>9.636331</td>\n",
       "      <td>158.854464</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>-0.022831</td>\n",
       "      <td>-0.022831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636092572</th>\n",
       "      <td>1.533369e+12</td>\n",
       "      <td>23.590937</td>\n",
       "      <td>37.875598</td>\n",
       "      <td>179.783729</td>\n",
       "      <td>5.908881</td>\n",
       "      <td>177.708475</td>\n",
       "      <td>1.533369e+09</td>\n",
       "      <td>5.956544</td>\n",
       "      <td>174.070033</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642122018</th>\n",
       "      <td>1.533383e+12</td>\n",
       "      <td>23.521470</td>\n",
       "      <td>37.869285</td>\n",
       "      <td>77.781947</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>179.273328</td>\n",
       "      <td>1.533383e+09</td>\n",
       "      <td>0.084344</td>\n",
       "      <td>177.574387</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642167061</th>\n",
       "      <td>1.533335e+12</td>\n",
       "      <td>23.587249</td>\n",
       "      <td>37.834346</td>\n",
       "      <td>281.104478</td>\n",
       "      <td>12.964179</td>\n",
       "      <td>280.288557</td>\n",
       "      <td>1.533335e+09</td>\n",
       "      <td>12.942367</td>\n",
       "      <td>280.018472</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677040700</th>\n",
       "      <td>1.533198e+12</td>\n",
       "      <td>23.572313</td>\n",
       "      <td>37.918328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.099565</td>\n",
       "      <td>198.329504</td>\n",
       "      <td>1.533198e+09</td>\n",
       "      <td>3.114936</td>\n",
       "      <td>177.379888</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp        lon        lat     heading      speed  \\\n",
       "mmsi                                                                   \n",
       "201100152  1.533299e+12  23.551511  37.940764         NaN   5.026128   \n",
       "201100182  1.533299e+12  23.516615  37.913168         NaN   6.758721   \n",
       "205339310  1.533196e+12  23.643233  37.926513         NaN   5.400000   \n",
       "205519630  1.533414e+12  23.649500  37.934933         NaN   0.786713   \n",
       "207137000  1.533434e+12  23.590206  37.894143  174.741078   2.476614   \n",
       "...                 ...        ...        ...         ...        ...   \n",
       "636092530  1.533130e+12  23.609716  37.880522  184.559361   9.483790   \n",
       "636092572  1.533369e+12  23.590937  37.875598  179.783729   5.908881   \n",
       "642122018  1.533383e+12  23.521470  37.869285   77.781947   0.108507   \n",
       "642167061  1.533335e+12  23.587249  37.834346  281.104478  12.964179   \n",
       "677040700  1.533198e+12  23.572313  37.918328         NaN   3.099565   \n",
       "\n",
       "               course  timestamp_sec   velocity     bearing  acceleration  \\\n",
       "mmsi                                                                        \n",
       "201100152  123.947895   1.533299e+09   5.071104  131.484013      0.004089   \n",
       "201100182  127.036773   1.533299e+09   6.737374  126.183349      0.002731   \n",
       "205339310  183.742857   1.533196e+09   5.437462  186.354599     -0.004437   \n",
       "205519630  141.380000   1.533414e+09   0.794071  170.195586     -0.000191   \n",
       "207137000  208.829309   1.533434e+09   2.490082  218.698913      0.000323   \n",
       "...               ...            ...        ...         ...           ...   \n",
       "636092530  163.990868   1.533130e+09   9.636331  158.854464      0.009524   \n",
       "636092572  177.708475   1.533369e+09   5.956544  174.070033      0.001556   \n",
       "642122018  179.273328   1.533383e+09   0.084344  177.574387      0.000008   \n",
       "642167061  280.288557   1.533335e+09  12.942367  280.018472      0.004251   \n",
       "677040700  198.329504   1.533198e+09   3.114936  177.379888      0.001894   \n",
       "\n",
       "            traj_id     label  \n",
       "mmsi                           \n",
       "201100152  0.000000  0.000000  \n",
       "201100182 -0.001453 -0.001453  \n",
       "205339310 -0.046512 -0.046512  \n",
       "205519630 -0.006993 -0.006993  \n",
       "207137000 -0.000759 -0.000759  \n",
       "...             ...       ...  \n",
       "636092530 -0.022831 -0.022831  \n",
       "636092572 -0.003390 -0.003390  \n",
       "642122018  0.000000  0.000000  \n",
       "642167061  0.000000  0.000000  \n",
       "677040700 -0.000870 -0.000870  \n",
       "\n",
       "[641 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['mmsi']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial) Number of segments: 9\n",
      "(Final-Useful) Number of port-based segments produced: 6\n"
     ]
    }
   ],
   "source": [
    "df_single = df.loc[df.mmsi == 237096700].copy()\n",
    "\n",
    "##It doesn't work\n",
    "###677040700\n",
    "#237562900\n",
    "#201100152\n",
    "###576082000\n",
    "#642167061\n",
    "\n",
    "#It works!\n",
    "######201100182#####4,18\n",
    "#####205519630\n",
    "######237096700#####6,10\n",
    "\n",
    "\n",
    "df_single.sort_values('timestamp', inplace=True)\n",
    "df_single.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_single = helper.fix_trajectories(df_single.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_single.copy()\n",
    "tmp.traj_id = tmp.traj_id.apply(str)\n",
    "\n",
    "\n",
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(tmp.copy())\n",
    "st_viz.create_canvas('Prototype Plot')\n",
    "\n",
    "cmap = st_viz.add_categorical_colormap('Category10', 'traj_id')\n",
    "st_viz.add_glyph(color=cmap, legend_label='Regions\\' outline points')\n",
    "st_viz.add_map_tile(provider='CARTODBPOSITRON')\n",
    "st_viz.add_hover_tooltips([('mmsi', '@mmsi'), ('traj_id', '@traj_id'), ('timestamp', '@timestamp')])\n",
    "\n",
    "\n",
    "regions_points_viz = st_visualizer.st_visualizer()\n",
    "regions_points_viz.set_data(regions_points.copy())\n",
    "regions_points_viz.set_figure(st_viz.figure)\n",
    "regions_points_viz.create_source()\n",
    "regions_points_viz.add_polygon(fill_color=None, line_color='crimson', legend_label='Regions\\' outline points')\n",
    "\n",
    "\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial) Number of port-based segments: 6\n",
      "(Intermediate) Number of temporal-gap-based segments: 11\n",
      "(Final-Useful) Number of trips produced: 10\n"
     ]
    }
   ],
   "source": [
    "df_single.sort_values('timestamp', inplace=True)\n",
    "\n",
    "df_single2 = df_single.copy()\n",
    "df_single2.loc[:, 'timestamp'] = df_single2.timestamp / 10**3\n",
    "\n",
    "df_single2 = helper.temporal_segmentation(df_single2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_single2.copy()\n",
    "tmp.trip_id = tmp.trip_id.apply(str)\n",
    "tmp.loc[:, 'date'] = pd.to_datetime(tmp.timestamp, unit='s').astype(str)\n",
    "\n",
    "\n",
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(tmp.copy())\n",
    "st_viz.create_canvas('Prototype Plot')\n",
    "\n",
    "cmap = st_viz.add_categorical_colormap('Category20', 'trip_id')\n",
    "st_viz.add_glyph(color=cmap, legend_label='Regions\\' outline points')\n",
    "st_viz.add_map_tile(provider='CARTODBPOSITRON')\n",
    "st_viz.add_hover_tooltips([('mmsi', '@mmsi'), ('trip_id', '@trip_id'), ('timestamp', '@timestamp'), ('datetime', '@date')])\n",
    "\n",
    "\n",
    "regions_points_viz = st_visualizer.st_visualizer()\n",
    "regions_points_viz.set_data(regions_points.copy())\n",
    "regions_points_viz.set_figure(st_viz.figure)\n",
    "regions_points_viz.create_source()\n",
    "regions_points_viz.add_polygon(fill_color=None, line_color='crimson', legend_label='Regions\\' outline points')\n",
    "\n",
    "\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.resample()\n",
    "\n",
    "#df.resample('2s')\n",
    "\n",
    "#df.resample('5')\n",
    "\n",
    "#df.resample(freq='T')\n",
    "#df.resample(freq='A')\n",
    "#df.resample('2012-01-01', freq='A', periods=2)\n",
    "#df.resample('2012-01-01')\n",
    "#df.resample(\"A\")\n",
    "#df.resample('D')\n",
    "\n",
    "\n",
    "#df.resample('3T').sum()\n",
    "\n",
    "#Upsample the series into 30 second bins\n",
    "#df.resample('30S').asfreq()[0:5]\n",
    "#df.resample('2min').sum()\n",
    "\n",
    "\n",
    "\n",
    "#df_resampled = df.set_index('timestamp').resample('2s').pad()\n",
    "\n",
    "\n",
    "#df_resampled = df.resample('D', on='timestamp').mean()\n",
    "#print (df_resampled)\n",
    "\n",
    "\n",
    "#df.resample(pd.offsets.Second(10), on='timestamp')\n",
    "\n",
    "\n",
    "df.index = pd.to_datetime(df.index, unit='s')\n",
    "df_resampled = df.resample('2min').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_single2.drop(['index','geom'], axis=1).columns\n",
    "\n",
    "df_single2_align = df_single2.groupby(['mmsi','trip_id'], as_index=False).apply(lambda l: helper.temporal_alignment_v2(l, rate=1, method='linear', features=features, temporal_axis_name='datetime', temporal_name='timestamp', temporal_unit='s')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many trips were lost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( df_single2.groupby(['mmsi','trip_id']).groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( df_single2_align.groupby(['mmsi','trip_id']).groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(df_single2.copy())\n",
    "st_viz.create_canvas('Prototype Plot')\n",
    "st_viz.add_glyph(color='royalblue', legend_label='Non-Aligned Points')\n",
    "st_viz.add_map_tile(provider='CARTODBPOSITRON')\n",
    "\n",
    "points_align = st_visualizer.st_visualizer()\n",
    "points_align.set_data(df_single2_align.copy())\n",
    "points_align.set_figure(st_viz.figure)\n",
    "points_align.create_source()\n",
    "points_align.add_glyph(color='orangered', legend_label='Aligned Points')\n",
    "\n",
    "st_viz.figure.legend.click_policy = 'mute'\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> Γεωγραφικά Πληροφοριακά Συστήματα </h1>\n",
    "\n",
    "<h2> Εργαστηριακή Διάλεξη Mobility Data Analytics (MDA) III </h2>\n",
    "\n",
    "    Τμήμα Πληροφορικής, Πανεπιστήμιο Πειραιώς,\n",
    "    Data Science Lab. (datastories.org)\n",
    "    \n",
    "    Βοηθοί Εργαστηρίου\n",
    "<br>\n",
    "\n",
    "    Τριτσαρώλης Ανδρέας              Κοντούλης Ιωάννης\n",
    "       andrewt@unipi.gr              ikontoulis@unipi.gr\n",
    "\n",
    "<br><br>\n",
    "    \n",
    "<img src=\"res/logo-datastories2.png\" alt=\"drawing\" align=\"right\"/>\n",
    "    \n",
    "<img src=\"res/University-of-Piraeus-Logo.png\" alt=\"drawing\"  align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "* Hotpoints\n",
    "\n",
    "  * What are hotpoints\n",
    "  * Data preparation\n",
    "  * Recommended Algorithms and execution\n",
    "    \n",
    "    \n",
    "* Collective Movement\n",
    "\n",
    "  * What is a collective movement\n",
    "  * Why is it used\n",
    " \n",
    " \n",
    "* Evovling Clusters\n",
    "\n",
    "  * Why evolving clusters\n",
    "  * Data prep\n",
    "  * Algorithm explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Hotpoints\n",
    "\n",
    "Hotpoints are clusters of points that form at a specific place on the map. In Maritime data, for example, we expect hotpoints to form at places where a lot of vessels either pass through a lot (for example at the entrance of a bay, shown in <font color='red'>red</font>) or reside for extended periods of time (i.e. in a port, shown in <font color='blue'>blue</font> or a possible fishing hotspot).\n",
    "\n",
    "<img src=\"res/portp.png\" alt=\"drawing\" width=\"500\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'geom_helper' from 'C:\\\\Users\\\\Konstantinos\\\\Jupyter Notebook\\\\geom_helper.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(helper)\n",
    "importlib.reload(viz_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'EvolvingClustersKDT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-69cd7c25ac61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Documents'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DataStories-UniPi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EvolvingClusters'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mEvolvingClustersKDT\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevolving_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'EvolvingClustersKDT'"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'Documents', 'DataStories-UniPi', 'EvolvingClusters'))\n",
    "from EvolvingClustersKDT import evolving_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the appropriate data. Read a csv using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gis_labs_ais_brest_sample_60K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need 2 columns to procceed with hotpoint mining, __Latitude__ and __Longitude__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['lat', 'lon']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot our data on a map.\n",
    "\n",
    "### We first need to transform our Pandas DataFrame to Geopandas __GeoDataFrame__\n",
    "\n",
    "### Then we can vizualize our set of coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a 'geom' column that will contain the shapely Point object that we need. Then we will create a GeoDataFrame, specifing that the 'geom' column is the used geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = helper.getGeoDataFrame_v2(df, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_viz = st_visualizer.st_visualizer()\n",
    "st_viz.set_data(gdf)\n",
    "\n",
    "viz_express.plot_points_on_map(st_viz)\n",
    "st_viz.show_figures(notebook=True, notebook_url='http://localhost:8890')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haversine Formula \n",
    "\n",
    "The Haversine formula is perhaps the first equation to consider when understanding how to calculate distances on a sphere. The word \"Haversine\" comes from the function:\n",
    "\n",
    ">haversine(θ) = sin²(θ/2)\n",
    "\n",
    " \n",
    "\n",
    "The following equation where φ is latitude, λ is longitude, R is earth’s radius (mean radius = 6,371km) is how we translate the above formula to include latitude and longitude coordinates. Note that angles need to be in __radians__ to pass to trig functions:\n",
    "\n",
    ">a = sin²(φB - φA/2) + cos φA * cos φB * sin²(λB - λA/2)\n",
    "\n",
    ">c = 2 * atan2( √a, √(1−a) )\n",
    "\n",
    ">d = R ⋅ c\n",
    "\n",
    "#### The haversine implementation that is part of sklearn clustering algorithms that we will use (DBSCAN and OPTICS) need radians as input. We will use numpy to convert our coordinates to radians\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.radians(gdf[['lat', 'lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Algorithms and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "It's a density-based clustering algorithm\n",
    "\n",
    "\n",
    "Density associated with a point is obtained by counting the number of points in a region of specified radius ϵ around each point\n",
    "\n",
    "\n",
    "\n",
    "* points with density ⩾ __min_pts__ are considered as \"core points\"\n",
    "* noise and non-core points are discarded\n",
    "* clusters are formed around the core points\n",
    "* if two core points are within a radius ϵ, then they belong to the same cluster\n",
    "\n",
    "\n",
    "<img src=\"res/dbscan.png\" alt=\"drawing\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DBSCAN algorithm is available from the scikit-learn library.\n",
    "\n",
    "The parameters that we'll use are:\n",
    "\n",
    "The maximum distance between two samples for one to be considered as in the neighborhood of the other -> __1 Kilometer__ in distance \n",
    "\n",
    "The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself -> __One 50th__ of the sample size.\n",
    "\n",
    "The algorithm to be used by the NearestNeighbors module to compute pointwise distances and find nearest neighbors -> __Ball Tree__\n",
    "\n",
    "Metric -> __Haversine__ (as discussed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=1/6371., min_samples=len(gdf)//50, algorithm='ball_tree', metric='haversine').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print all unique clusters labels. Points clustered as -1 are considered __noise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(db.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compute and print the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.get_clusters_centers(X, db.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we will plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = gdf.copy()\n",
    "tmp.loc[:, 'cluster_labels'] = db.labels_\n",
    "tmp.cluster_labels = tmp.cluster_labels.apply(str)\n",
    "\n",
    "\n",
    "points = st_visualizer.st_visualizer()\n",
    "points.set_data(tmp.copy())\n",
    "points.create_canvas('Prototype Plot')\n",
    "\n",
    "cmap = points.add_categorical_colormap('Category10', 'cluster_labels')\n",
    "points.add_glyph(color=cmap, legend_group='cluster_labels')\n",
    "points.add_map_tile(provider='CARTODBPOSITRON')\n",
    "points.add_hover_tooltips([('mmsi', '@mmsi'), ('traj_id', '@traj_id'), ('timestamp', '@timestamp')])\n",
    "\n",
    "points.show_figures(notebook=True, notebook_url='http://localhost:8889')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTICS\n",
    "OPTICS Clustering stands for Ordering Points To Identify Cluster Structure. It draws inspiration from the DBSCAN clustering algorithm. It adds two more terms to the concepts of DBSCAN clustering. They are:\n",
    "\n",
    "* Core Distance: It is the minimum value of radius required to classify a given point as a core point. If the given point is not a Core point, then it’s Core Distance is undefined.\n",
    "\n",
    "<img src=\"res/core_distance.png\" alt=\"drawing\" width=\"500\" align='center'/>\n",
    "\n",
    "* Reachability Distance: It is defined with respect to another data point q(Let). The Reachability distance between a point p and q is the maximum of the Core Distance of p and the Euclidean Distance(or some other distance metric) between p and q. Note that The Reachability Distance is not defined if q is not a Core point.\n",
    "\n",
    "<img src=\"res/reachability_distance1.png\" alt=\"drawing\" width=\"500\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The OPTICS algorithm is also available from the scikit-learn library.\n",
    "\n",
    "The parameters that we'll use are:\n",
    "\n",
    "The maximum distance between two samples for one to be considered as in the neighborhood of the other -> __1 Kilometer__ in distance.\n",
    "\n",
    "The number of samples in a neighborhood for a point to be considered as a core point -> __One 50th__ of the sample size.\n",
    "\n",
    "Metric -> __Haversine__ (as discussed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OPTICS(max_eps=1/6371, min_samples=len(gdf)//50, metric='haversine').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print all unique clusters labels. Points clustered as -1 are considered __noise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(optics.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compute and print the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.get_clusters_centers(X, optics.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we will plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = gdf.copy()\n",
    "tmp.loc[:, 'cluster_labels'] = optics.labels_\n",
    "tmp.cluster_labels = tmp.cluster_labels.apply(str)\n",
    "\n",
    "\n",
    "points = st_visualizer.st_visualizer()\n",
    "points.set_data(tmp.copy())\n",
    "points.create_canvas('Prototype Plot')\n",
    "\n",
    "cmap = points.add_categorical_colormap('Category10', 'cluster_labels')\n",
    "points.add_glyph(color=cmap, legend_group='cluster_labels')\n",
    "points.add_map_tile(provider='CARTODBPOSITRON')\n",
    "points.add_hover_tooltips([('mmsi', '@mmsi'), ('traj_id', '@traj_id'), ('timestamp', '@timestamp')])\n",
    "\n",
    "points.show_figures(notebook=True, notebook_url='http://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a collective movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An informal collective movement definition could be: \"a large enough amount of objects moving along\n",
    "paths close to each other for a certain time\". These objects could vary from animals (e.g.\n",
    "wolves, birds, lions, etc.) to human transportation means (e.g. cars, airplanes and vessels).\n",
    "Discovering these patterns can give us an insight regarding the behavior of these moving objects,\n",
    "for instance on hunting (wolves, lions), migration (birds), traffic monitoring (cars) and fishing\n",
    "pressure (fishing vessels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/gps.png\" alt=\"drawing\" width=\"1000\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple types of collective movement patterns have been introduced, including:\n",
    "* Flocks\n",
    "* Convoys\n",
    "* Swarms\n",
    "* Evolving Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is it used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collective movement can be of use to geospatial researchers and industry proffesionals because it is\n",
    "able to model a phenomenon that can be used to mine a lot of valuable information from multiple \"angles\".\n",
    "\n",
    "For example, in the maritime domain, illegal transshipments between two or more veseels can be very easily detected by a collective movement mining algorithm. An illegal transshipment is definded as the illegal exchange of goods between vessels at sea. If a collective movement pattern is systematically being mined under dubious circumstances, an official can use the knowledge base generated by the algorithm in order to detect any malicious activity (including illegal trashippments). \n",
    "\n",
    "Another useful way of interpreting the results of a collective movement mining algorithm is using them as a profiler that can clusters multiple objects into groups that have a lot of similarities based on their movement. That knowledge, in turn, can be used to compress a given dataset or to cluster new object that may appear in order to analyze and predict their behaviour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evovling Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why evolving clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvolvingClusters is used to discover collective movement behaviour (like flocks and convoys) by monitoring the activity of multiple clusters through time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given: a set T of moving objects, where the trajectory of\n",
    "each object consists of r pairs (pi, ti), a minimum cardinality threshold c, a maximum distance\n",
    "threshold θ, and a minimum time duration threshold d, an Evolving Cluster (C, tstart, tend, tpi)\n",
    "is a subset C ε T of the moving objects population, |C| >= c, which appeared at time point tstart\n",
    "and remained alive until time point tend (with tendtstart >= d) during the lifetime (tstart, tend) of\n",
    "which the participating moving objects were spatially connected with respect to distance θ and\n",
    "cluster type tp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 1 presents the algorithms corpus. In particular it discovers evolving clusters in a\n",
    "trajectory dataset D, where moving objects' locations arrive at predefined timepoints (e.g.\n",
    "every 60 sec.) or, in other words, at a \f",
    "xed (and aligned amongst all objects) sampling rate.\n",
    "In the following paragraphs we provide a thorough explanation regarding its operation.\n",
    "Algorithm 1 is responsible of using the results provided by Algorithm 3 in a sequential manner.\n",
    "Essentially Algorithm 1 uses the results of Algorithm 2 and decides if the available data in\n",
    "the form of ActiveP atterns (patterns previously mined) and CurrentClusters (clusters formed\n",
    "based on the location of moving objects at the current time-slice) are eligible to be used as input\n",
    "to Algorithm 3. If not (either set is empty), the algorithm either moves the clusters currently\n",
    "active to the ActiveP atterns set (if ActiveP atterns = ;) or moves all the patterns that satisfy\n",
    "the thresholds given from ActiveP atterns to ClosedP atterns (if CurrentClusters = ;).\n",
    "Algorithm 3 takes all the following cases into consideration: (for pattern Cti at time ti and\n",
    "Cti+1 at time ti+1)\n",
    "\n",
    "1. The patterns are identical (Cti = Cti+1)\n",
    "2. The patterns have no common objects (intersection(Cti, Cti+1) is empty)\n",
    "3. The pattern Cti is a subset of Cti+1 (Cti < Cti+1)\n",
    "4. The pattern Cti+1 is a subset of Cti (Cti+1 < Cti)\n",
    "5. The patterns contain some common objects (intersection(Cti, Cti+1) is not empty , intersection(Cti, Cti+1) < Cti, Cti+1)\n",
    "\n",
    "Therefore, the algorithm operates as follows:\n",
    "* For every pair of consecutive (with respect to time) pattens, if the cardinality of their\n",
    "intersection is greater than c, add it to the ActiveP atterns set (lines: 4{7).\n",
    "* For every pattern in Cti+1, if the list of its intersections with all of the patterns in Cti\n",
    "doesn't contain the pattern, add it to the ActiveP atterns set as a new pattern (lines:\n",
    "8{9).\n",
    "* For every pattern in Cti , if it is not part of the ActiveP atterns set, add it to the\n",
    "InactiveP atterns set (line: 11).\n",
    "* Replace each group of duplicate patterns in the ActiveP atterns set, with a single record\n",
    "of each pattern and substitute its starting and ending timestamps with the oldest starting\n",
    "and newest ending timestamps available in the duplicate group (lines: 12{17).\n",
    "\n",
    "We observe that in all cases the pattern that ought to be maintained through time is the\n",
    "intersection of Cti and Cti+1. Cases 2 and 3 require some extra attention. Regarding case 2,\n",
    "the intersection is an empty set. As a result, Cti+1 should be maintained and added to the\n",
    "ActiveP atterns set. Case 3 dictates that both the new superset and the previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/algo1.png\" alt=\"drawing\" width=\"800\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/algo2.png\" alt=\"drawing\" width=\"800\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/algo3.png\" alt=\"drawing\" width=\"800\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that will be mined by EvolvingClusters needs to:\n",
    "* Contain columns 'lat', 'lon' and 'datetime'.\n",
    "* Be uniformly sampled with respect to time __and__ time aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('gis_labs_ais_brest_sample_60K_aligned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.groupby('datetime').groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[res_mcs, res_mc] = evolving_clusters(df1, distance_threshold=1500, min_cardinality=5, time_threshold=5, disable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in res_mcs.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = res_mcs.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[:, 'datetime'] = pd.to_datetime(df1.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df1.loc[(df1.mmsi.isin(cluster.clusters)) & (df1.datetime.between(cluster.st, cluster.et, inclusive=True))].copy()\n",
    "tmp.loc[:, 'mmsi'] = tmp.mmsi.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = st_visualizer.st_visualizer()\n",
    "points.set_data(tmp.copy())\n",
    "points.create_canvas('Prototype Plot')\n",
    "\n",
    "# points.add_temporal_filter(step_ms=60*10**3)\n",
    "\n",
    "points.add_numerical_filter(filter_mode='<=', numeric_name='ts', step=60, callback_policy='value')\n",
    "\n",
    "cmap = points.add_categorical_colormap('Category10', 'mmsi')\n",
    "points.add_glyph(color=cmap, legend_group='mmsi')\n",
    "points.add_map_tile(provider='CARTODBPOSITRON')\n",
    "points.add_hover_tooltips([('mmsi', '@mmsi'), ('traj_id', '@traj_id'), ('timestamp', '@timestamp')])\n",
    "\n",
    "points.show_figures(notebook=True, notebook_url='http://localhost:8888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
